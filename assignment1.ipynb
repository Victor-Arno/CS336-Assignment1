{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a9f9be",
   "metadata": {},
   "source": [
    "# 2.1 Unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51823c0",
   "metadata": {},
   "source": [
    "## <font color=\"red\">(a)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd3af06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79bbc8",
   "metadata": {},
   "source": [
    "## <font color=\"red\">(b)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d1a9f783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "print(chr(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b96406cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test\\x00string'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = \"this is a test\" + chr(0) + \"string\"\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd3af6",
   "metadata": {},
   "source": [
    "## <font color=\"red\">(c)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b419c473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\u0000string\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a4e42",
   "metadata": {},
   "source": [
    "# 2.2 Unicode  Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33837821",
   "metadata": {},
   "source": [
    "## <font color=\"red\">(a)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ef10866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'h\\x00\\x00\\x00e\\x00\\x00\\x00l\\x00\\x00\\x00l\\x00\\x00\\x00o\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UTF-8编码\n",
    "\"hello\".encode(\"utf-8\")  # b'hello' - ASCII字符保持原样\n",
    "# 每个ASCII字符正好是1字节\n",
    "\n",
    "# UTF-16编码\n",
    "\"hello\".encode(\"utf-16-le\")  # b'h\\x00e\\x00l\\x00l\\x00o\\x00'\n",
    "# 每个ASCII字符变为2字节，其中一半是空字节(0x00)\n",
    "\n",
    "# UTF-32编码\n",
    "\"hello\".encode(\"utf-32-le\")  # b'h\\x00\\x00\\x00e\\x00\\x00\\x00l\\x00\\x00\\x00l\\x00\\x00\\x00o\\x00\\x00\\x00'\n",
    "# 每个ASCII字符变为4字节，其中3/4是空字节"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe239b5",
   "metadata": {},
   "source": [
    "## <font color=\"red\">(b)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62184799",
   "metadata": {},
   "source": [
    "原因: 它逐个字节解码UTF-8，而UTF-8字符可能是多字节的.\n",
    "破坏了多字节序列.UTF-8多字节字符必须作为一个整体解码\n",
    ",拆分字节会得到完全不同的字符或无效序列.\n",
    "eg. \"你\" 的UTF-8编码是 b'\\xe4\\xbd\\xa0'\n",
    "如果逐个字节解码,会得到:\n",
    "b'\\xe4' -> 'ä'\n",
    "b'\\xbd' -> '½'\n",
    "b'\\xa0' -> ' '\n",
    "这不是一个有效的UTF-8字符序列,因此会被解码为替换字符(U+FFFD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "963130c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])\n",
    "\n",
    "string = \"hello\"\n",
    "decode_utf8_bytes_to_str_wrong(string.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10128bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe4\\xbd\\xa0'\n",
      "你\n"
     ]
    }
   ],
   "source": [
    "print(\"你\".encode(\"utf-8\"))\n",
    "print(\"你\".encode(\"utf-8\").decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9bc0b57e",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\xe4\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "print(b'\\xe4'.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ebd76",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m你好\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdecode_utf8_bytes_to_str_wrong\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m, in \u001b[0;36mdecode_utf8_bytes_to_str_wrong\u001b[1;34m(bytestring)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_utf8_bytes_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "string = \"你\"\n",
    "decode_utf8_bytes_to_str_wrong(string.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450bb06b",
   "metadata": {},
   "source": [
    "## <font color=\"red\">(c)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b2e06",
   "metadata": {},
   "source": [
    "\"中\".encode(\"utf-8\")  # b'\\xe4\\xb8\\xad' 是有效的三字节序列\n",
    "<br>\n",
    "#但如果拆分：b'\\xe4\\xb8' 就只有两个字节，但缺少最后一个字节，也是无效的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501c9534",
   "metadata": {},
   "source": [
    "# 2.4 Pre-tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7152845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你好', '，', '这是一个测试字符串', '！']\n",
      "['some', ' text', ' that', ' i', \"'ll\", ' pre', '-', 'tokenize']\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "print(re.findall(PAT, \"你好，这是一个测试字符串！\"))\n",
    "print(re.findall(PAT, \"some text that i'll pre-tokenize\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95431d83",
   "metadata": {},
   "source": [
    "# 2.5 Experimenting with BPE Tokenizer Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45dcfd",
   "metadata": {},
   "source": [
    "相比https://github.com/heng380/cs336-assignment1的改进"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0955d2b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 新tokenizer相比旧版本的主要改变和优化\n",
    "\n",
    "### 1. **注释和文档改进**\n",
    "- **所有注释中文化**：将英文注释全部替换为中文注释，便于中文用户理解\n",
    "- **增加详细文档**：为每个函数和类添加了详细的中文文档字符串\n",
    "\n",
    "### 2. **分块处理优化**\n",
    "- **换行符规范化**：在`get_chunk`函数中增加了换行符统一处理，将`\\r\\n`和`\\r`都转换为`\\n`\n",
    "- **分割标记更改**：将分块分割标记从`b\"<|endoftext|>\"`改为`b\"\\n\"`，更符合实际文本分割需求\n",
    "\n",
    "### 3. **核心算法性能优化**\n",
    "\n",
    "#### `count_pair_frequencies`方法优化\n",
    "```python\n",
    "# 旧版本：每次循环都计算len(word)\n",
    "for word, freq in tokens_counter.items():\n",
    "    for i in range(len(word) - 1):\n",
    "\n",
    "# 新版本：避免重复计算长度，提高性能\n",
    "for word, freq in tokens_counter.items():\n",
    "    word_len = len(word)  # 优化：避免重复计算长度\n",
    "    for i in range(word_len - 1):\n",
    "```\n",
    "\n",
    "#### `find_max_pair`方法重写\n",
    "- **旧版本**：使用`max(counts, key=lambda x: (counts[x], x))`\n",
    "- **新版本**：手动实现循环比较，避免lambda函数开销，并修复了字典序选择逻辑\n",
    "- **重要修复**：当频率相同时，选择字典序更大的pair（与原始代码一致）\n",
    "\n",
    "#### `merge_tokens`方法重大优化\n",
    "**主要改进：**\n",
    "- **原地更新**：不再创建新的Counter对象，而是原地更新现有的tokens_counter\n",
    "- **pair_counts维护**：新增pair_counts参数，在合并时实时更新字节对频率\n",
    "- **批量操作**：使用tokens_to_remove和tokens_to_add列表进行批量更新\n",
    "- **性能提升**：避免重复计算pair_counts，显著提高训练速度\n",
    "\n",
    "### 4. **训练过程优化**\n",
    "\n",
    "#### `train_BPE`方法改进\n",
    "- **进程数限制**：`num_processes = min(multiprocessing.cpu_count(), 8)`，避免过度并行化\n",
    "- **chunksize优化**：使用`chunksize=max(1, len(chunks) // num_processes)`提高并行效率\n",
    "- **pair_counts单次初始化**：在训练循环外初始化pair_counts，避免重复计算\n",
    "- **进度条优化**：提前计算目标词汇量，进度条显示更准确\n",
    "\n",
    "### 5. **Tokenizer类编码优化**\n",
    "- **移除tqdm进度条**：在`encode`方法中移除了tqdm进度条，提高编码性能\n",
    "- **保持功能完整性**：所有核心功能保持不变\n",
    "\n",
    "### 6. **代码结构和可读性改进**\n",
    "- **类和方法注释**：为所有类和方法添加了详细的中文注释\n",
    "- **变量命名更清晰**：如`tokens_to_remove`、`tokens_to_add`等变量名更直观\n",
    "- **代码逻辑分组**：使用中文注释对代码进行逻辑分组\n",
    "\n",
    "## 性能提升总结\n",
    "\n",
    "1. **训练速度提升**：通过pair_counts的单次初始化和原地更新，显著减少重复计算\n",
    "2. **内存效率提升**：避免创建不必要的Counter对象，减少内存分配\n",
    "3. **并行效率优化**：合理的进程数限制和chunksize设置\n",
    "4. **算法复杂度优化**：减少重复的长度计算和字典操作\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ca28f",
   "metadata": {},
   "source": [
    "# 对于因果掩码的理解"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
